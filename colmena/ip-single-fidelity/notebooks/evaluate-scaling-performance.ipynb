{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Scaling Performance\n",
    "Measure how well each application uses resources as we scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import interpolate\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "\n",
    "params = {'legend.fontsize': 8,\n",
    "         'axes.labelsize': 9,\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize': 6,\n",
    "         'ytick.labelsize': 6}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_re = r\"^(?P<date>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3}) - (?P<module>\\S+) - (?P<level>[A-Z]+) - (?P<message>[\\s\\S]*?)(?=^\\d{4})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Runs\n",
    "Get the data from the productive-level runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = list(Path(\"prod-runs\").glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_data(path: Path):\n",
    "    \"\"\"Get the data about a run\n",
    "    \n",
    "    Args:\n",
    "        path: Path to the run\n",
    "    Returns:\n",
    "        (dict) Data about the run\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the basic information\n",
    "    output = dict(path=path, study=path.name.split(\"_\")[-1])\n",
    "    with open(path.joinpath('run_params.json')) as fp:\n",
    "        run_params = json.load(fp)\n",
    "    output['num_nodes'] = run_params['nnodes']\n",
    "    for k in ['random', 'retrain_frequency', 'nodes_per_task']:\n",
    "        output[k] = run_params.get(k)\n",
    "    \n",
    "    # Get the start-time\n",
    "    with open(path.joinpath('runtime.log')) as fp:\n",
    "        line = fp.readline().strip()\n",
    "        start_time = datetime.strptime(line.split(\" - \")[0].strip(), \"%Y-%m-%d %H:%M:%S,%f\")\n",
    "    output['start_time'] = start_time\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([get_run_data(x) for x in runs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>study</th>\n",
       "      <th>num_nodes</th>\n",
       "      <th>random</th>\n",
       "      <th>retrain_frequency</th>\n",
       "      <th>nodes_per_task</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prod-runs/256-nodes_update-8</td>\n",
       "      <td>update-8</td>\n",
       "      <td>256</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-07-07 21:53:41.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prod-runs/256-nodes_random</td>\n",
       "      <td>random</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-03-28 06:02:32.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prod-runs/128-nodes_random</td>\n",
       "      <td>random</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-04-04 17:05:48.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prod-runs/256-nodes_no-retrain</td>\n",
       "      <td>no-retrain</td>\n",
       "      <td>256</td>\n",
       "      <td>None</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-07-02 03:36:48.282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             path       study  num_nodes random  \\\n",
       "0    prod-runs/256-nodes_update-8    update-8        256   None   \n",
       "1      prod-runs/256-nodes_random      random        256   True   \n",
       "2      prod-runs/128-nodes_random      random        128   True   \n",
       "3  prod-runs/256-nodes_no-retrain  no-retrain        256   None   \n",
       "\n",
       "   retrain_frequency  nodes_per_task              start_time  \n",
       "0                  8               4 2021-07-07 21:53:41.933  \n",
       "1                 50               4 2021-03-28 06:02:32.191  \n",
       "2                 50               4 2021-04-04 17:05:48.192  \n",
       "3               2000               4 2021-07-02 03:36:48.282  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tools for Assessing Utilization\n",
    "Retrieve the amount of resources at each time and the resources allocated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_log(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load the Colmena runtime log\n",
    "    \n",
    "    Args:\n",
    "        path: Path to the run files\n",
    "    Returns:\n",
    "        DataFrame of the log messages\n",
    "    \"\"\"\n",
    "    with open(path.joinpath('runtime.log')) as fp:\n",
    "        log_data = pd.DataFrame([x.groupdict() for x in re.finditer(log_re, fp.read(), re.MULTILINE)])\n",
    "    log_data['datetime'] = log_data['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S,%f').timestamp())\n",
    "    return log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resource_allocation(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Get the resource allocation over time for a run\n",
    "    \n",
    "    Args:\n",
    "        path: Path to the run files\n",
    "    Returns:\n",
    "        Resource allocations at different times. Each row indicates\n",
    "        when the allocation changed from one strategy to another\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load in the runtime log\n",
    "    log_data = load_log(path)\n",
    "    start_time = log_data['datetime'].iloc[0]\n",
    "    end_time = log_data['datetime'].iloc[-1]\n",
    "        \n",
    "    # Get the resource messages\n",
    "    log_data.query('module==\"colmena.thinker.resources\"', inplace=True)\n",
    "    \n",
    "    # Record allocation changes\n",
    "    rec_re = re.compile(r'Transferred (?P<count>\\d+) slots from (?P<from>\\w+) to (?P<to>\\w+)')\n",
    "    log_data['parsed'] = log_data['message'].apply(rec_re.match)\n",
    "    log_data = log_data[[x is not None for x in log_data['parsed']]]\n",
    "    resource_changes = pd.DataFrame(log_data['parsed'].apply(lambda x: x.groupdict()).tolist())\n",
    "    resource_changes['datetime'] = log_data['datetime'].values\n",
    "    \n",
    "    # Convert count to an int\n",
    "    resource_changes['count'] = resource_changes['count'].apply(int)\n",
    "    \n",
    "    # Infer the total number of slots\n",
    "    #  Assume we assign all nodes from None to a pool\n",
    "    total_counts = resource_changes[resource_changes['from'] == \"None\"]['count'].sum()\n",
    "    \n",
    "    # Write down the initial allocation (all in None)\n",
    "    state = dict((x, 0) for x in ['inference', 'training', 'simulation', 'time'])\n",
    "    state['None'] = total_counts\n",
    "    \n",
    "    # Measure how they change over time\n",
    "    states = [state.copy()]\n",
    "    for _, change in resource_changes.iterrows():\n",
    "        # Record the new time\n",
    "        state['time'] = change['datetime'] - start_time\n",
    "        \n",
    "        # Update the state\n",
    "        state[change['to']] += change['count']\n",
    "        state[change['from']] -= change['count']\n",
    "        \n",
    "        # Add to the history\n",
    "        states.append(state.copy())\n",
    "        \n",
    "    # Add in a last time for the end\n",
    "    state['time'] = end_time - start_time\n",
    "    states.append(state)\n",
    "    \n",
    "    return pd.DataFrame(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utilization(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Get the utilization of different resources as a function of time.\n",
    "    \n",
    "    We determine utilization as when a task is actually executing on a worker\n",
    "    \n",
    "    Args:\n",
    "        path: Path to the run files\n",
    "    Returns:\n",
    "        Amount of slots used by each task as a function of time.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the log\n",
    "    log_data = load_log(path)\n",
    "    start_time = log_data['datetime'].iloc[0]\n",
    "    \n",
    "    # Get the number of slots per QC task\n",
    "    with open(path.joinpath('run_params.json')) as fp:\n",
    "        run_params = json.load(fp)\n",
    "        slots_per_qc = run_params['nodes_per_task']\n",
    "    \n",
    "    # Compile the run time for each completed tasks\n",
    "    events = []\n",
    "    for ttype, dpath in zip(['training', 'inference', 'simulation'], \n",
    "                           ['training-results.json', 'inference-records.json', 'simulation-results.json']):\n",
    "        dpath = path.joinpath(dpath)\n",
    "        if not dpath.is_file(): \n",
    "            continue\n",
    "            \n",
    "        # Process each result\n",
    "        with open(dpath) as fp:\n",
    "            for line in fp:\n",
    "                data = json.loads(line)\n",
    "                events.append({\n",
    "                    'time': data['time_compute_started'] - start_time,\n",
    "                    'type': ttype,\n",
    "                    'change': slots_per_qc if ttype == 'simulation' else 1\n",
    "                })  # Compute starting\n",
    "                events.append({\n",
    "                    'time': data['time_compute_started'] + data['time_running'] - start_time,\n",
    "                    'type': ttype,\n",
    "                    'change': -slots_per_qc if ttype == 'simulation' else -1\n",
    "                })  # Compute finishing           \n",
    "    events = pd.DataFrame(events)\n",
    "    \n",
    "    # Keep track of the total state\n",
    "    state = dict((x, 0) for x in ['inference', 'training', 'simulation', 'time'])\n",
    "    states = [state.copy()]\n",
    "    for _, event in events.sort_values('time').iterrows():\n",
    "        state['time'] = event['time']\n",
    "        state[event['type']] += event['change']\n",
    "        states.append(state.copy())\n",
    "    \n",
    "    return pd.DataFrame(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Allocation and Utilization Over Time\n",
    "See how well we do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_run = results.query('num_nodes==256 and retrain_frequency==8 and study==\"update-8\"').iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "allocation = get_resource_allocation(target_run['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "utilization = get_utilization(target_run['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x136.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5, 1.9))\n",
    "\n",
    "order = ['inference', 'training', 'simulation']\n",
    "color = ['firebrick', 'mediumblue', 'goldenrod']\n",
    "\n",
    "# Plot the allocation and usage for the first type\n",
    "ax.fill_between(allocation['time'] / 3600, allocation['inference'], step='post', alpha=0.2, color=color[0], edgecolor='none')\n",
    "ax.fill_between(utilization['time'] / 3600, utilization['inference'], step='post', color=color[0], label=order[0], edgecolor='none')\n",
    "\n",
    "# Plot the utilization for the remaining task types\n",
    "for i in range(1, len(color)):\n",
    "    start = allocation[order[:i]].sum(axis=1)\n",
    "    ax.fill_between(allocation['time'] / 3600, allocation[order[i]] + start, y2=start, step='post', alpha=0.2, color=color[i], edgecolor='none')\n",
    "    \n",
    "    # Determine the start point for the utilization\n",
    "    start = interpolate.interp1d(allocation['time'], start, kind='previous', fill_value='extrapolate')(utilization['time'])\n",
    "    ax.fill_between(utilization['time'] / 3600, utilization[order[i]] + start, y2=start, step='post', color=color[i], label=order[i], edgecolor='none')\n",
    "\n",
    "ax.set_ylim(0, max(allocation[order].sum(axis=1)))\n",
    "ax.legend(loc='center', ncol=2)\n",
    "ax.set_xlabel('Time (h)')\n",
    "ax.set_ylabel('Nodes Allocated/Used')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/utilization-over-time.pdf')\n",
    "fig.savefig('figures/utilization-over-time.png', dpi=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the amount dedicated to each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hours_allocated(path: Path):\n",
    "    \"\"\"Compute the hours allocated to each task\"\"\"\n",
    "    \n",
    "    # Compute the allocation\n",
    "    allocation = get_resource_allocation(path)\n",
    "    \n",
    "    # Get the amount of time for each stage\n",
    "    time_incr = allocation['time'].diff()[1:].values\n",
    "    \n",
    "    # For each task, compute the total run time\n",
    "    return dict(\n",
    "        (t, np.dot(allocation[t].values[:-1], time_incr) / 3600) for t in ['training', 'inference', 'simulation']\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hours_used(path: Path):\n",
    "    \"\"\"Compute the hours used for each task\"\"\"\n",
    "    \n",
    "    # Compute the allocation\n",
    "    allocation = get_utilization(path)\n",
    "    \n",
    "    # Get the amount of time for each stage\n",
    "    time_incr = allocation['time'].diff()[1:].values\n",
    "    \n",
    "    # For each task, compute the total run time\n",
    "    return dict(\n",
    "        (t, np.dot(allocation[t].values[:-1], time_incr) / 3600) for t in ['training', 'inference', 'simulation']\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': 76.50876111110051,\n",
       " 'inference': 30.07434888548321,\n",
       " 'simulation': 1415.7855300045014}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_allocated = compute_hours_allocated(target_run['path'])\n",
    "total_allocated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_used = compute_hours_used(target_run['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilization: 86.3%\n"
     ]
    }
   ],
   "source": [
    "print(f'Utilization: {sum(total_used.values())/sum(total_allocated.values())*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for the \"non-retrain\" run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': 0.0,\n",
       " 'inference': 34.366008894178606,\n",
       " 'simulation': 1480.845653330485}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_hours_allocated(results.query('num_nodes==256 and retrain_frequency>=1000')['path'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Latency of Creating Simulations\n",
    "We want to measure the difference in time between when a simulation completing and the next being launched. We will do by getting statistics of the three operations:\n",
    "1. Time to send results from worker to Thinker\n",
    "1. Time for thinker to submit the next task\n",
    "1. Time for task to launch on a worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_result_transfer_overhead(path: Path) -> np.ndarray:\n",
    "    \"\"\"Assess the time it takes a result to move from worker to thinker\n",
    "    \n",
    "    Args:\n",
    "        path: Path to the run files\n",
    "    Returns:\n",
    "        List of the observed latencies\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the path to the simulation results\n",
    "    res_path = path / \"simulation-results.json\"\n",
    "    latencies = []\n",
    "    with open(res_path) as fp:\n",
    "        for line in fp:\n",
    "            data = json.loads(line)\n",
    "            latencies.append(\n",
    "                data[\"time_serialize_results\"] + data[\"time_deserialize_results\"] +\n",
    "                data[\"time_result_received\"] - (data[\"time_compute_started\"] + data[\"time_running\"])\n",
    "            )\n",
    "    return np.array(latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_request_transfer_overhead(path: Path) -> np.ndarray:\n",
    "    \"\"\"Assess the time it takes for a task to move from Thinker to worker\"\"\"\n",
    "    \n",
    "    # Get the path to the simulation results\n",
    "    res_path = path / \"simulation-results.json\"\n",
    "    latencies = []\n",
    "    with open(res_path) as fp:\n",
    "        for line in fp:\n",
    "            data = json.loads(line)\n",
    "            latencies.append(\n",
    "                data[\"time_compute_started\"] - data[\"time_created\"]\n",
    "            )\n",
    "    return np.array(latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_response_time(path: Path) -> np.ndarray:\n",
    "    \"\"\"Measure the time it takes for the Thinker to generate a new molecule\"\"\"\n",
    "    \n",
    "    # Load the logs\n",
    "    log_data = load_log(path)\n",
    "    \n",
    "    # Get the time the jobs where received\n",
    "    result_received = log_data[log_data.message.str.startswith('Client received a run_simulation')]\n",
    "    \n",
    "    # Get the actions taken after receiving a result\n",
    "    request_sent = log_data[np.logical_or(log_data.message.str.startswith('Client sent a run_simulation'),\n",
    "                                          log_data.message.str.startswith('Transferred 4 slots from simulation'))]\n",
    "    \n",
    "    # Remove tasks that have not yet been responded to\n",
    "    result_received = result_received[result_received.datetime < request_sent.datetime.max()]\n",
    "    \n",
    "    # Determine the time of the next action after a result was received\n",
    "    next_action = interpolate.interp1d(request_sent.datetime, request_sent.datetime, kind='next')(result_received.datetime - 2e-3)\n",
    "    \n",
    "    return (next_action - result_received.datetime).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_response_times(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Profile the various latencies involved in responding to a simulation completeing\n",
    "    \n",
    "    Args:\n",
    "        path: Path to the simulation files\n",
    "    Returns:\n",
    "        Assessment of the various aspects of latency\n",
    "    \"\"\"\n",
    "    \n",
    "    output = []\n",
    "    for task, times in {\n",
    "        'result_transfer': assess_result_transfer_overhead(path),\n",
    "        'request_transfer': assess_request_transfer_overhead(path),\n",
    "        'response_time': assess_response_time(path)\n",
    "    }.items():\n",
    "        output.append({\n",
    "            'task': task,\n",
    "            'count': len(times),\n",
    "            'mean': np.mean(times),\n",
    "            'median': np.median(times),\n",
    "            '75th': np.percentile(times, 75),\n",
    "            'max': np.max(times)\n",
    "        })\n",
    "    return pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>75th</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result_transfer</td>\n",
       "      <td>354</td>\n",
       "      <td>0.858702</td>\n",
       "      <td>0.647106</td>\n",
       "      <td>1.232552</td>\n",
       "      <td>3.681340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request_transfer</td>\n",
       "      <td>354</td>\n",
       "      <td>0.192682</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>0.045279</td>\n",
       "      <td>2.027974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>response_time</td>\n",
       "      <td>354</td>\n",
       "      <td>0.072189</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.081750</td>\n",
       "      <td>1.097000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               task  count      mean    median      75th       max\n",
       "0   result_transfer    354  0.858702  0.647106  1.232552  3.681340\n",
       "1  request_transfer    354  0.192682  0.009932  0.045279  2.027974\n",
       "2     response_time    354  0.072189  0.054000  0.081750  1.097000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_response_times(target_run['path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Latency of Creating Simulations\n",
    "We want to measure the difference in time between when a simulation completing and the next being launched. We will do by getting statistics of the three operations:\n",
    "1. Time to send results from worker to Thinker\n",
    "1. Time for thinker to submit the next task\n",
    "1. Time for task to launch on a worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_result_transfer_overhead(path: Path, records: str = 'simulation-results.json',\n",
    "                                    successful: bool = None) -> np.ndarray:\n",
    "    \"\"\"Assess the time it takes a result to move from worker to thinker\n",
    "    \n",
    "    Args:\n",
    "        path: Path to the run files\n",
    "        records: Name of the record file\n",
    "        successful: Whether to get only the successful, failed tasks or both\n",
    "    Returns:\n",
    "        List of the observed latencies\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the path to the simulation results\n",
    "    res_path = path / records\n",
    "    latencies = []\n",
    "    with open(res_path) as fp:\n",
    "        for line in fp:\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # If desired, get only failed or successful tasks\n",
    "            if successful is not None:\n",
    "                if data['success'] != successful:\n",
    "                    continue\n",
    "                \n",
    "            latencies.append(\n",
    "                data[\"time_serialize_results\"] + data[\"time_deserialize_results\"] +\n",
    "                data[\"time_result_received\"] - (data[\"time_compute_started\"] + data[\"time_running\"])\n",
    "            )\n",
    "    return np.array(latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_request_transfer_overhead(path: Path, records: str = 'simulation-results.json') -> np.ndarray:\n",
    "    \"\"\"Assess the time it takes for a task to move from Thinker to worker\"\"\"\n",
    "    \n",
    "    # Get the path to the simulation results\n",
    "    res_path = path / records\n",
    "    latencies = []\n",
    "    with open(res_path) as fp:\n",
    "        for line in fp:\n",
    "            data = json.loads(line)\n",
    "            latencies.append(\n",
    "                data[\"time_compute_started\"] - data[\"time_created\"]\n",
    "            )\n",
    "    return np.array(latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_response_time(path: Path) -> np.ndarray:\n",
    "    \"\"\"Measure the time it takes for the Thinker to generate a new molecule\"\"\"\n",
    "    \n",
    "    # Load the logs\n",
    "    log_data = load_log(path)\n",
    "    \n",
    "    # Get the time the jobs where received\n",
    "    result_received = log_data[log_data.message.str.startswith('Client received a run_simulation')]\n",
    "    \n",
    "    # Get the actions taken after receiving a result\n",
    "    request_sent = log_data[np.logical_or(log_data.message.str.startswith('Client sent a run_simulation'),\n",
    "                                          log_data.message.str.startswith('Transferred 4 slots from simulation'))]\n",
    "    \n",
    "    # Remove tasks that have not yet been responded to\n",
    "    result_received = result_received[result_received.datetime < request_sent.datetime.max()]\n",
    "    \n",
    "    # Determine the time of the next action after a result was received\n",
    "    next_action = interpolate.interp1d(request_sent.datetime, request_sent.datetime, kind='next')(result_received.datetime - 2e-3)\n",
    "    \n",
    "    return (next_action - result_received.datetime).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_response_times(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Profile the various latencies involved in responding to a simulation completeing\n",
    "    \n",
    "    Args:\n",
    "        path: Path to the simulation files\n",
    "    Returns:\n",
    "        Assessment of the various aspects of latency\n",
    "    \"\"\"\n",
    "    \n",
    "    output = []\n",
    "    for task, times in {\n",
    "        'result_transfer': assess_result_transfer_overhead(path),\n",
    "        'request_transfer': assess_request_transfer_overhead(path),\n",
    "        'response_time': assess_response_time(path)\n",
    "    }.items():\n",
    "        output.append({\n",
    "            'task': task,\n",
    "            'count': len(times),\n",
    "            'mean': np.mean(times),\n",
    "            'median': np.median(times),\n",
    "            '75th': np.percentile(times, 75),\n",
    "            'min': np.min(times),\n",
    "            'max': np.max(times)\n",
    "        })\n",
    "    return pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>75th</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result_transfer</td>\n",
       "      <td>354</td>\n",
       "      <td>0.858702</td>\n",
       "      <td>0.647106</td>\n",
       "      <td>1.232552</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>3.681340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request_transfer</td>\n",
       "      <td>354</td>\n",
       "      <td>0.192682</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>0.045279</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>2.027974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>response_time</td>\n",
       "      <td>354</td>\n",
       "      <td>0.072189</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.081750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.097000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               task  count      mean    median      75th       min       max\n",
       "0   result_transfer    354  0.858702  0.647106  1.232552  0.006875  3.681340\n",
       "1  request_transfer    354  0.192682  0.009932  0.045279  0.003559  2.027974\n",
       "2     response_time    354  0.072189  0.054000  0.081750  0.000000  1.097000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_response = profile_response_times(target_run['path'])\n",
    "sim_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task      result_transferrequest_transferresponse_time\n",
       "count                                             1062\n",
       "mean                                           1.12357\n",
       "median                                        0.711038\n",
       "75th                                           1.35958\n",
       "min                                          0.0104339\n",
       "max                                            6.80631\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_response.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of the result transfer times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5, 2.))\n",
    "\n",
    "bins = np.logspace(-2, 1, 32)\n",
    "\n",
    "# Get only the results\n",
    "result_times = assess_result_transfer_overhead(target_run['path'], successful=True)\n",
    "ax.hist(result_times, bins=bins, label='Success', alpha=0.5)\n",
    "\n",
    "result_times = assess_result_transfer_overhead(target_run['path'], successful=False)\n",
    "ax.hist(result_times, bins=bins, label='Failure', alpha=0.5)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Latency (s)')\n",
    "ax.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the median task times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simulation_times(path: Path) -> np.ndarray:\n",
    "    \"\"\"Get the time required for each simulation\"\"\"\n",
    "    \n",
    "    sim_tasks = pd.read_json(path / 'simulation-results.json', lines=True)\n",
    "    return sim_tasks['time_running'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median simulation time: 2711.48s\n"
     ]
    }
   ],
   "source": [
    "sim_runtime = get_simulation_times(target_run['path'])\n",
    "print(f'Median simulation time: {np.median(sim_runtime):.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Inference Overheads\n",
    "We need to look at the node start up time and the time it takes to communicate requests/results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = load_log(target_run['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median startup time: 101.46 s\n"
     ]
    }
   ],
   "source": [
    "def assess_startup_time(path: Path) -> np.ndarray:\n",
    "    \"\"\"Get the time it requires for the workers to startup\"\"\"\n",
    "    \n",
    "    # Load the data\n",
    "    log_data = load_log(path)\n",
    "    start_time = log_data['datetime'].iloc[0]\n",
    "    log_data['time'] = log_data['datetime'] - start_time\n",
    "    \n",
    "    # Determine when nodes are allocated\n",
    "    #node_registered = log_data[log_data.message.str.startswith('[MAIN] Adding manager')]\n",
    "    \n",
    "    # Determine when compute starts on a node\n",
    "    inf_log = pd.read_json(path / 'inference-records.json', lines=True)\n",
    "    inf_log['node_id'] = inf_log['task_info'].apply(lambda x: x['executor'])\n",
    "    \n",
    "    # Determine time times nodes are requested\n",
    "    allocation = get_resource_allocation(path)\n",
    "    allocation['n_requested'] = allocation['inference'].diff()\n",
    "    requests = allocation[allocation['n_requested'] > 0]\n",
    "    request_times = np.repeat(requests['time'].values, requests['n_requested'])\n",
    "    \n",
    "    # Determine when they are no longer needed\n",
    "    finishes = allocation[allocation['n_requested'] < 0]\n",
    "    \n",
    "    # Loop over each round of inference requests\n",
    "    start_times = []\n",
    "    for batch_start, batch_end in zip([0] + finishes.time.tolist(), finishes['time']):\n",
    "        # Get the requests that occurred during the batch\n",
    "        batch_reqs = request_times[np.logical_and(request_times < batch_end, request_times > batch_start)]\n",
    "        \n",
    "        # Get the times node start compute after the first nodes are requested in this batch\n",
    "        \n",
    "        #batch_regs = node_registered.query(f'time < {batch_end} and time > {batch_reqs.min()}')\n",
    "        batch_cmps = inf_log.query(f'time_compute_started < {batch_end + start_time} and time_compute_started > {batch_reqs.min() + start_time}').copy()\n",
    "        batch_cmps.sort_values('time_compute_started', inplace=True)\n",
    "        batch_cmps.drop_duplicates('node_id', keep='first', inplace=True)\n",
    "        compute_starts = batch_cmps['time_compute_started'] - start_time\n",
    "        \n",
    "        # Add in the response times\n",
    "        for s, e in zip(batch_reqs, compute_starts):\n",
    "            start_times.append(e - s)\n",
    "    \n",
    "    # Get only the start times >0. \n",
    "    #  There is a problem in that Parsl will create more nodes than we request\n",
    "    start_times = np.array([s for s in start_times if s > 0])\n",
    "    return start_times\n",
    "print(f'Median startup time: {np.median(assess_startup_time(target_run[\"path\"])):.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result transfer times: Median 0.222s - Mean 0.262s - Max 4.787s\n"
     ]
    }
   ],
   "source": [
    "result_trans = assess_result_transfer_overhead(target_run['path'], 'inference-records.json')\n",
    "print(f'Result transfer times: Median {np.median(result_trans):.3f}s - Mean {np.mean(result_trans):.3f}s - Max {np.max(result_trans):.3f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_execution_times(path: Path, warmed_only: bool = False) -> np.ndarray:\n",
    "    \"\"\"Get the execution times for the inference tasks\n",
    "    \n",
    "    Args:\n",
    "        path: Path to result directory\n",
    "        warmed_only: Whether to get only the warmed containers or not\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the start time\n",
    "    log_data = load_log(path)\n",
    "    start_time = log_data['datetime'].iloc[0]\n",
    "    \n",
    "    # Get the inference results\n",
    "    inf_results = pd.read_json(path / 'inference-records.json', lines=True)\n",
    "    inf_results['time_compute_started'] -= start_time\n",
    "    inf_results['node_id'] = inf_results['task_info'].apply(lambda x: x['executor'])\n",
    "    \n",
    "    # Get the dividers for each batch of inference\n",
    "    allocation = get_resource_allocation(path)\n",
    "    allocation['n_requested'] = allocation['inference'].diff()\n",
    "    \n",
    "    batch_edges = [0] + allocation[allocation['n_requested'] < 0]['time'].values.tolist()\n",
    "    \n",
    "    # For each batch, separate \"first\" jobs per node from \"warmed\" jobs\n",
    "    warmed_jobs = []\n",
    "    first_jobs = []\n",
    "    for s, e in zip(batch_edges, batch_edges[1:]):\n",
    "        # Get the jobs during this batch\n",
    "        jobs = inf_results.query(f'{s} < time_compute_started < {e}').copy()\n",
    "        assert len(jobs) == 16 * 32\n",
    "        \n",
    "        # Label the first jobs\n",
    "        jobs['is_first'] = False\n",
    "        jobs.sort_values('time_compute_started', inplace=True)\n",
    "        jobs.loc[jobs.drop_duplicates('node_id', keep='first').index, 'is_first'] = True\n",
    "        \n",
    "        # Append results\n",
    "        warmed_jobs.extend(jobs.query('not is_first')['time_running'].values.tolist())\n",
    "        first_jobs.extend(jobs.query('is_first')['time_running'].values.tolist())\n",
    "    \n",
    "    return np.array(warmed_jobs), np.array(first_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmed_inf, first_inf = get_execution_times(target_run['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmed inference times: Median 79.72s - Mean 49.43s - Max 84.64s\n",
      "First inference times: Median 99.41s - Mean 99.48s - Max 101.21s\n"
     ]
    }
   ],
   "source": [
    "print(f'Warmed inference times: Median {np.median(warmed_inf):.2f}s - Mean {np.mean(warmed_inf):.2f}s - Max {np.max(warmed_inf):.2f}s')\n",
    "print(f'First inference times: Median {np.median(first_inf):.2f}s - Mean {np.mean(first_inf):.2f}s - Max {np.max(first_inf):.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Training Overheads\n",
    "We need to look at the time to receive results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_times(path: Path) -> np.ndarray:\n",
    "    \"\"\"Get the time required for training\"\"\"\n",
    "    \n",
    "    results = pd.read_json(path / 'training-results.json', lines=True)\n",
    "    return results['time_running'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training times: Median 2966.43s - Mean 3263.85s - Max 8772.40s\n"
     ]
    }
   ],
   "source": [
    "train_times = get_training_times(target_run['path'])\n",
    "print(f'Training times: Median {np.median(train_times):.2f}s - Mean {np.mean(train_times):.2f}s - Max {np.max(train_times):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result transfer times: Median 5.69s - Mean 5.48s - Max 7.50s\n"
     ]
    }
   ],
   "source": [
    "result_trans = assess_result_transfer_overhead(target_run['path'], 'training-results.json')\n",
    "print(f'Result transfer times: Median {np.median(result_trans):.2f}s - Mean {np.mean(result_trans):.2f}s - Max {np.max(result_trans):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
